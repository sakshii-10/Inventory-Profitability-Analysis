# üìà Vendor Performance Optimization & Profitability Analysis

## üìò Overview
This project executes an **end-to-end data science pipeline** to analyze and optimize vendor performance.  

---

## üß© Dataset
**Dataset Name:** `Vendor Sales Summary`  
Contains aggregated sales, cost, and revenue data for various suppliers over a defined period.

| Feature | Description | Example |
|----------|--------------|----------|
| `Vendor_ID` | Unique identifier for each supplier | V1024 |
| `Total_Revenue` | Gross sales generated by the vendor | $85,000 |
| `Cost_of_Goods` | Total cost associated with goods sold | $60,000 |
| `Total_Sales_Units` | Volume of products sold | 5,500 |
| `Vendor_Tier` | Preliminary classification of vendor (e.g., A, B, C) | Tier B |
| `Region` | Geographic region of the vendor's operations | North America |

---

## ‚öôÔ∏è Tools and Technologies

| Category | Tool / Library | Purpose |
|-----------|----------------|----------|
| **Data Engineering** | Python (`pandas`, `io`, `psycopg2`) | Data cleaning, transformation, and optimized database loading |
| **Database Management** | PostgreSQL (`COPY` command) | High-speed data storage and querying |
| **Statistical Analysis** | Python (`scipy.stats.ttest_ind`) | Hypothesis testing and statistical validation of business metrics |
| **Data Visualization** | Power BI (`Vendor_Performance.pbix`) | Dynamic dashboard creation for executive reporting |

---

## üß± Project Pipeline

### 1Ô∏è‚É£ Data Loading & Feature Engineering (`Data Load and Exploration (1).ipynb`)
- **Loading Optimization:** Implemented a high-performance loading mechanism using **Python‚Äôs in-memory buffer (`io`)** with PostgreSQL **`COPY`**.
- **Impact:** Achieved up to **10√ó faster ingestion** of the large-scale dataset compared to traditional SQL `INSERT` methods.
- **Feature Engineering:**
  - Derived the business metric:  
    ```python
    ProfitMargin = (Total_Revenue - Cost_of_Goods) / Total_Revenue
    ```
  - Standardized data types for consistency and SQL compatibility.
- **Database Load:** Cleaned and engineered data loaded into a PostgreSQL table for analysis.

---

### 2Ô∏è‚É£ Exploratory Data Analysis (EDA) & Statistical Validation (`EDA with Python.ipynb`)
Performed deep analytical and statistical testing to uncover objective insights.

| Analysis | Description |
|-----------|-------------|
| **Metric Calculation** | Calculated average `ProfitMargin` and `TotalSalesDollars` by vendor tier. |
| **Hypothesis Testing** | Formulated and tested: <br> *H‚ÇÄ: There is no significant difference in Profit Margin between top-tier and low-tier vendors.* |
| **Statistical Method** | Used **Two-Sample Welch‚Äôs T-Test** to compare means between tiers. |
| **Conclusion** | Obtained a **P-value < 0.05**, confirming a statistically significant difference in vendor profitability. |

---

### 3Ô∏è‚É£ Business Intelligence (BI) Dashboard Development
Developed a dynamic and interactive **Power BI dashboard** (`Vendor_Performance.pbix`) serving as the strategic visualization layer.

---

## üìä Dashboard Insights & Key Results

| Metric | Insight | Actionable Outcome |
|--------|----------|--------------------|
| **Profit Margin** | Top-tier vendors deliver significantly higher margins (**P < 0.05**). | Renegotiate terms with low-performing vendors. |
| **Sales Distribution** | 20% of vendors contribute 80% of total revenue. | Prioritize strategic partnerships and risk management for top-tier vendors. |
| **Cost Analysis** | Certain regions exhibit unusually high `Cost_of_Goods`. | Conduct cost-reduction reviews and explore alternative sourcing options. |

---

## üß† Key Learnings
- **Data Engineering:** Leveraging PostgreSQL `COPY` and Python I/O methods drastically improves ETL efficiency on large datasets.  
- **Statistical Rigor:** Hypothesis testing transforms descriptive metrics into statistically validated business insights.  
- **Visualization:** Translating analytical results into executive-ready dashboards bridges the gap between data science and business strategy.
